{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "28UZvzD8lvYN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ionut/Projects/sdg4ad\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import imageio\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from src.utils import load_config, print_config, set_seed\n",
        "\n",
        "os.chdir(\"..\")\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "seed: 42\n",
            "file_paths: ['data/Splits/PN/split_1_train.txt', 'data/Splits/PN/split_2_train.txt', 'data/Splits/PN/split_3_train.txt']\n",
            "output_paths: ['output/synthetic_images_PN/split_1', 'output/synthetic_images_PN/split_2', 'output/synthetic_images_PN/split_3']\n",
            "sam_checkpoint: weights/sam_vit_h_4b8939.pth\n",
            "model_type: vit_h\n",
            "device: cpu\n",
            "points_per_side: 32\n",
            "sigma: 5\n",
            "keep_ratio: 0.5\n",
            "lower_th_a: 80\n",
            "upper_th_a: 160\n",
            "lower_th_b: 80\n",
            "upper_th_b: 240\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cfg = load_config(\"config/config_synthetic_generation.yaml\")\n",
        "print_config(cfg)\n",
        "set_seed(cfg[\"seed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBaHiwWmyarw"
      },
      "source": [
        "## Canny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_index_of_edgiest_grape(cfg, imgs):\n",
        "    \"\"\"\n",
        "    Returns the index of the edgiest grape in the list of images.\n",
        "\n",
        "    It uses two Canny edge detectors with different thresholds and returns the index of the image\n",
        "    with the highest difference in edge count. The edge count is normalized by the number of non-black pixels.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration dictionary.\n",
        "        imgs (list): List of images.\n",
        "\n",
        "    Returns:\n",
        "        int: Index of the edgiest grape.\n",
        "    \"\"\"\n",
        "    edge_counts = []\n",
        "    for img in imgs:\n",
        "        img = cv2.GaussianBlur(img, (cfg[\"sigma\"], cfg[\"sigma\"]), 0)\n",
        "        num_edges_a = cv2.countNonZero(cv2.Canny(img, cfg[\"lower_th_a\"], cfg[\"upper_th_a\"]))\n",
        "        num_edges_b = cv2.countNonZero(cv2.Canny(img, cfg[\"lower_th_b\"], cfg[\"upper_th_b\"]))\n",
        "        non_black_pixels = np.count_nonzero(np.any(img != [0, 0, 0], axis=-1))\n",
        "        normalized_edge_count = abs(num_edges_a - num_edges_b) / (non_black_pixels)\n",
        "        edge_counts.append(normalized_edge_count)\n",
        "    return np.argmax(edge_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image(image_path, target_resolution):\n",
        "    resolutions = {\n",
        "    \"720p\": (1280, 720),\n",
        "    \"1080p\": (1920, 1080),\n",
        "    \"1440p\": (2560, 1440),\n",
        "    \"4k\": (3840, 2160)\n",
        "    }\n",
        "\n",
        "    target_height, target_width = resolutions[target_resolution]\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    aspect_ratio = width / height\n",
        "    target_ratio = target_width / target_height\n",
        "\n",
        "    if aspect_ratio > target_ratio:\n",
        "        new_width = target_width\n",
        "        new_height = int(new_width / aspect_ratio)\n",
        "    else:\n",
        "        new_height = target_height\n",
        "        new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    return resized_image\n",
        "\n",
        "\n",
        "def get_mask_generator(cfg):\n",
        "    \"\"\"\n",
        "    Returns the SAM mask generator.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): The configuration dictionary.\n",
        "\n",
        "    Returns:\n",
        "        SamAutomaticMaskGenerator: The mask generator.\n",
        "    \"\"\"\n",
        "    sam = sam_model_registry[cfg[\"model_type\"]](checkpoint=cfg[\"sam_checkpoint\"]).to(device=cfg[\"device\"])\n",
        "    mask_generator = SamAutomaticMaskGenerator(model=sam, points_per_side=cfg[\"points_per_side\"])\n",
        "    return mask_generator\n",
        "\n",
        "\n",
        "def filter_masks_by_area(masks, keep_ratio):\n",
        "    \"\"\"\n",
        "    Filters a list of masks based on their area. It returns the top masks based on the keep_ratio,\n",
        "    but only if their area is greater than the mean.\n",
        "\n",
        "    Args:\n",
        "        masks (list): A list of dictionaries where each dictionary represents a mask and has an 'area' key.\n",
        "        keep_ratio (float): The ratio of masks to keep. The value should be between 0 (exclusive) and 1 (inclusive).\n",
        "\n",
        "    Returns:\n",
        "        list: The filtered masks.\n",
        "    \"\"\"\n",
        "    assert 0 < keep_ratio <= 1, \"keep_ratio should be between 0 (exclusive) and 1 (inclusive).\"\n",
        "\n",
        "    # Sort masks by area\n",
        "    masks = sorted(masks, key=lambda x: x['area'])\n",
        "\n",
        "    # Find the index of the first mask with area >= mean area\n",
        "    areas = [mask['area'] for mask in masks]\n",
        "    mean_area = np.mean(areas)\n",
        "    index = np.searchsorted(areas, mean_area)\n",
        "\n",
        "    # Keep the top masks only if their area is greater than the mean area\n",
        "    index = max(index, int(len(masks) * (1-keep_ratio)))\n",
        "    return masks[index:]\n",
        "\n",
        "\n",
        "def generate_masks(image, mask_generator, keep_ratio):\n",
        "    \"\"\"\n",
        "    Generates masks for the input image. The masks are filtered by area.\n",
        "\n",
        "    Args:\n",
        "        image (np.array): The input image.\n",
        "        mask_generator (SamAutomaticMaskGenerator): The mask generator.\n",
        "        keep_ratio (float): The ratio of masks to keep. The value should be between 0 (exclusive) and 1 (inclusive).\n",
        "\n",
        "    Returns:\n",
        "        list: The generated masks.\n",
        "    \"\"\"\n",
        "    masks = mask_generator.generate(image)\n",
        "    masks = filter_masks_by_area(masks, keep_ratio)\n",
        "    masks = [mask['segmentation'] for mask in masks]\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXxf8ENamf6s"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PqKs-B7qmkAr"
      },
      "outputs": [],
      "source": [
        "def read_file_list(file_path):\n",
        "    \"\"\"\n",
        "    Reads the file list and returns the paths of the good and bad grapes.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the file list.\n",
        "\n",
        "    Returns:\n",
        "        list: The paths of the good grapes.\n",
        "        list: The paths of the bad grapes.\n",
        "    \"\"\"\n",
        "    good_paths = []\n",
        "    bad_paths = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            path, label = line.strip().split()\n",
        "            if label == '0':  # Good grape\n",
        "                good_paths.append(path)\n",
        "            else:  # Grape with anomaly\n",
        "                bad_paths.append(path)\n",
        "    return good_paths, bad_paths\n",
        "\n",
        "\n",
        "def write_log(index, good_image_path, bad_image_path, log_folder):\n",
        "    \"\"\"\n",
        "    Writes the log of the generated anomaly.\n",
        "\n",
        "    Args:\n",
        "        index (int): The index of the anomaly.\n",
        "        good_image_path (str): The path of the good grape image.\n",
        "        bad_image_path (str): The path of the bad grape image.\n",
        "        log_folder (str): The path of the log folder.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(log_folder, f\"log_anomaly_{index}.txt\"), \"a\") as f:\n",
        "        f.write(f\"Anomaly {index} generated with:\\n\")\n",
        "        f.write(f\"Good image: {os.path.basename(good_image_path)}\\n\")\n",
        "        f.write(f\"Bad image: {os.path.basename(bad_image_path)}\\n\")\n",
        "\n",
        "\n",
        "def get_biggest_component(mask):\n",
        "    \"\"\"\n",
        "    Returns the biggest component of the mask.\n",
        "\n",
        "    Args:\n",
        "        mask (np.array): The input mask.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The biggest component of the mask.\n",
        "    \"\"\"\n",
        "    _, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
        "    largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
        "    return (labels == largest_label).astype(np.uint8)\n",
        "\n",
        "\n",
        "def save_segmentations(img, masks, output_folder):\n",
        "    \"\"\"\n",
        "    Saves the segmentations of the input image.\n",
        "\n",
        "    Args:\n",
        "        img (np.array): The input image.\n",
        "        masks (list): The list of masks.\n",
        "        output_folder (str): The output folder.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    for i, mask in enumerate(masks):\n",
        "        mask = mask.astype(np.uint8)\n",
        "        mask = get_biggest_component(mask)\n",
        "        imageio.imwrite(os.path.join(output_folder, f\"segmented_{i}.png\"), np.dstack((img, mask*255)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blending"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PoissonBlending(source, destination, bad_mask, good_mask, cloning_type, plot=False):\n",
        "    \"\"\"\n",
        "    Blends the source image with the destination image using Poisson blending.\n",
        "\n",
        "    Args:\n",
        "        source (np.array): The source image.\n",
        "        destination (np.array): The destination image.\n",
        "        bad_mask (np.array): The mask of the bad grape.\n",
        "        good_mask (np.array): The mask of the good grape.\n",
        "        cloning_type (int): The type of cloning.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The blended image.\n",
        "    \"\"\"\n",
        "    # Get dimensions of the bad mask\n",
        "    x_bad, y_bad, w_bad, h_bad = cv2.boundingRect(bad_mask)\n",
        "    center_bad = (x_bad + w_bad // 2, y_bad + h_bad // 2)\n",
        "\n",
        "    # Set the center for the blending to be the centroid of the good grape\n",
        "    moments = cv2.moments(good_mask)\n",
        "    center_good = (int(moments['m10'] / moments['m00']), int(moments['m01'] / moments['m00']))\n",
        "\n",
        "    # Calculate offset for aligning bad mask with good mask centroid\n",
        "    offset = (center_good[0] - center_bad[0], center_good[1] - center_bad[1])\n",
        "\n",
        "    # # Move the bad grape to the centroid of the good mask\n",
        "    M = np.float32([[1, 0, offset[0]], [0, 1, offset[1]]])\n",
        "    bad_mask = cv2.warpAffine(bad_mask, M, (destination.shape[1], destination.shape[0]), flags=cv2.INTER_NEAREST)\n",
        "    source = cv2.warpAffine(source, M, (destination.shape[1], destination.shape[0]))\n",
        "\n",
        "    if plot:\n",
        "        _, ax = plt.subplots(1, 2)\n",
        "        ax[0].imshow(source)\n",
        "        ax[0].set_title(\"Bad grape aligned\")\n",
        "        ax[1].imshow(bad_mask)\n",
        "        ax[1].set_title(\"Bad mask aligned\")\n",
        "        plt.show()\n",
        "\n",
        "    # # Get the intersection of the aligned masks\n",
        "    intersection = cv2.bitwise_and(bad_mask, good_mask)\n",
        "\n",
        "    if plot:\n",
        "        plt.imshow(intersection)\n",
        "        plt.title(\"Intersection\")\n",
        "        plt.show()\n",
        "\n",
        "    # Get the bounding box of the intersection\n",
        "    _, _, w_inter, h_inter = cv2.boundingRect(intersection)\n",
        "\n",
        "    # Add padding around destination to make sure that the source will not be outside the image\n",
        "    destination = cv2.copyMakeBorder(destination, h_inter, h_inter, w_inter, w_inter, cv2.BORDER_REFLECT101)\n",
        "    center_good = (center_good[0] + w_inter, center_good[1] + h_inter)\n",
        "\n",
        "    # Poisson blending\n",
        "    blended = cv2.seamlessClone(source, destination, intersection*255, center_good, cloning_type)\n",
        "\n",
        "    # Remove the padding\n",
        "    blended = blended[h_inter:-h_inter, w_inter:-w_inter]\n",
        "\n",
        "    if plot:\n",
        "        save_segmentations(blended, [intersection], \"./notebooks/output\")\n",
        "\n",
        "    return blended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rotation and Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_rotation_matrix(mask, reference_mask, plot=False):\n",
        "    \"\"\"\n",
        "    Returns the rotation matrix to align the principal axes of the mask with the reference mask.\n",
        "\n",
        "    Args:\n",
        "        mask (np.array): The mask to align.\n",
        "        reference_mask (np.array): The reference mask.\n",
        "        plot (bool): Whether to plot the masks and the principal axes.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The rotation matrix.\n",
        "    \"\"\"\n",
        "    # Find indices of non-zero elements (row, column) -> (y, x)\n",
        "    mask_points = np.argwhere(mask)\n",
        "    ref_points = np.argwhere(reference_mask)\n",
        "\n",
        "    # Fit PCA on mask and reference mask points\n",
        "    pca = PCA(n_components=2)\n",
        "    pca.fit(mask_points)\n",
        "    ref_pca = PCA(n_components=2)\n",
        "    ref_pca.fit(ref_points)\n",
        "\n",
        "    # Get primary principal components from PCA (y,x)\n",
        "    principal_axis = pca.components_[0]\n",
        "    ref_principal_axis = ref_pca.components_[0]\n",
        "\n",
        "    # Only consider the direction of the principal axis in the positive y direction\n",
        "    if principal_axis[0] < 0:\n",
        "        principal_axis = -principal_axis\n",
        "    if ref_principal_axis[0] < 0:\n",
        "        ref_principal_axis = -ref_principal_axis\n",
        "\n",
        "    # Compute angles of principal axes (positive -> clockwise)\n",
        "    angle = np.rad2deg(np.arctan2(principal_axis[0], principal_axis[1]))\n",
        "    ref_angle = np.rad2deg(np.arctan2(ref_principal_axis[0], ref_principal_axis[1]))\n",
        "\n",
        "    # Compute rotation angle\n",
        "    rotation_angle = ref_angle - angle\n",
        "\n",
        "    # Get rotation matrix\n",
        "    moments = cv2.moments(mask)\n",
        "    center = (moments['m10'] / moments['m00'], moments['m01'] / moments['m00'])\n",
        "    rotation_matrix = cv2.getRotationMatrix2D(center, -rotation_angle, 1.0)  # positive angle -> counter-clockwise\n",
        "\n",
        "    if plot:\n",
        "        print(\"Principal axis:\", principal_axis)\n",
        "        print(\"Reference principal axis:\", ref_principal_axis)\n",
        "        print(\"Angle:\", angle)\n",
        "        print(\"Reference angle:\", ref_angle)\n",
        "        print(\"Rotation angle:\", rotation_angle)\n",
        "\n",
        "        _, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "        # Show the mask and the direction of the principal axes\n",
        "        axs[0].imshow(mask, cmap=\"gray\")\n",
        "        axs[0].set_title(\"Mask\")\n",
        "        axs[0].quiver(center[0], center[1], principal_axis[1], -principal_axis[0], color=\"green\", scale=5)\n",
        "\n",
        "        # Show the reference mask and the direction of the principal axes\n",
        "        ref_moments = cv2.moments(reference_mask)\n",
        "        center_reference = (ref_moments['m10'] / ref_moments['m00'], ref_moments['m01'] / ref_moments['m00'])\n",
        "        axs[1].imshow(reference_mask, cmap=\"gray\")\n",
        "        axs[1].set_title(\"Reference mask\")\n",
        "        axs[1].quiver(center_reference[0], center_reference[1], ref_principal_axis[1], -ref_principal_axis[0], color=\"green\", scale=5)\n",
        "        plt.show()\n",
        "\n",
        "    return rotation_matrix\n",
        "\n",
        "\n",
        "def rotate_grape(image, mask, reference_mask, plot=False):\n",
        "    \"\"\"\n",
        "    Rotates the grape (image and mask) to align the principal axes of the mask with the reference mask.\n",
        "\n",
        "    Args:\n",
        "        image (np.array): The image of the grape.\n",
        "        mask (np.array): The mask of the grape.\n",
        "        reference_mask (np.array): The reference mask.\n",
        "        plot (bool): Whether to plot the principal axes.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The rotated image.\n",
        "        np.array: The rotated mask.\n",
        "    \"\"\"\n",
        "    # Get rotation matrix\n",
        "    rotation_matrix = get_rotation_matrix(mask, reference_mask, plot)\n",
        "\n",
        "    # Rotate the image\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Rotate the mask\n",
        "    rotated_mask = cv2.warpAffine(mask, rotation_matrix, (mask.shape[1], mask.shape[0]), flags=cv2.INTER_NEAREST)\n",
        "\n",
        "    if plot:\n",
        "        _, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        axs[0].imshow(rotated_image)\n",
        "        axs[0].set_title(\"Rotated image\")\n",
        "        axs[1].imshow(rotated_mask, cmap=\"gray\")\n",
        "        axs[1].set_title(\"Rotated mask\")\n",
        "        plt.show()\n",
        "\n",
        "    return rotated_image, rotated_mask\n",
        "\n",
        "\n",
        "def scale_grape(image, mask, reference_mask, plot=False):\n",
        "    \"\"\"\n",
        "    Scales the grape (image and mask) to match the size of the reference mask.\n",
        "\n",
        "    Args:\n",
        "        image (np.array): The image of the grape.\n",
        "        mask (np.array): The mask of the grape.\n",
        "        reference_mask (np.array): The reference mask.\n",
        "        plot (bool): Whether to plot the masks.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The scaled image.\n",
        "        np.array: The scaled mask.\n",
        "    \"\"\"\n",
        "    # Compute moments\n",
        "    moments = cv2.moments(mask)\n",
        "    ref_moments = cv2.moments(reference_mask)\n",
        "\n",
        "    # Compute the scale factor\n",
        "    scale_factor = np.sqrt(ref_moments['m00'] / moments['m00'])\n",
        "\n",
        "    # Scale the image\n",
        "    img_interp = cv2.INTER_CUBIC if scale_factor > 1 else cv2.INTER_AREA\n",
        "    scaled_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=img_interp)\n",
        "\n",
        "    # Scale the mask\n",
        "    scaled_mask = cv2.resize(mask, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    if plot:\n",
        "        _, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        axs[0].imshow(scaled_image)\n",
        "        axs[0].set_title(\"Scaled image\")\n",
        "        axs[1].imshow(scaled_mask, cmap=\"gray\")\n",
        "        axs[1].set_title(\"Scaled mask\")\n",
        "        plt.show()\n",
        "\n",
        "    return scaled_image, scaled_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huck8oxNgm_F"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-h-mBoCEgqr4"
      },
      "outputs": [],
      "source": [
        "def generate_synthetic_image(cfg, img_good, img_bad, mask_generator, plot):\n",
        "    \"\"\"\n",
        "    Generates a synthetic image by blending a bad grape onto an image of good grapes.\n",
        "\n",
        "    Args:\n",
        "        cfg (dict): Configuration dictionary.\n",
        "        img_good (np.array): The image of good grapes.\n",
        "        img_bad (np.array): The image of bad grapes.\n",
        "        mask_generator (SamAutomaticMaskGenerator): The mask generator.\n",
        "        plot (bool): Whether to plot and save the intermediate steps.\n",
        "\n",
        "    Returns:\n",
        "        np.array: The synthetic image.\n",
        "    \"\"\"\n",
        "    # Generate masks for the good image and choose one randomly\n",
        "    good_masks = generate_masks(img_good, mask_generator, cfg[\"keep_ratio\"])\n",
        "    good_idx = random.randint(0, len(good_masks) - 1)\n",
        "    good_mask = good_masks[good_idx].astype(np.uint8)      \n",
        "\n",
        "    # Generate masks for the bad image and choose the edgiest one\n",
        "    bad_masks = generate_masks(img_bad, mask_generator, cfg[\"keep_ratio\"])\n",
        "    \n",
        "    bad_grapes = [img_bad * mask[:, :, None] for mask in bad_masks]\n",
        "    bad_idx = get_index_of_edgiest_grape(cfg, bad_grapes)\n",
        "    bad_mask = bad_masks[bad_idx].astype(np.uint8)\n",
        "    bad_grape = bad_grapes[bad_idx]\n",
        "\n",
        "    # Check if the masks are made of more than one connected component\n",
        "    bad_mask = get_biggest_component(bad_mask)\n",
        "    good_mask = get_biggest_component(good_mask)  \n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(bad_mask)\n",
        "        plt.title(\"Bad mask\")\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(bad_grape)\n",
        "        plt.title(\"Bad grape\")\n",
        "        plt.show()\n",
        "\n",
        "        good_grape = img_good * good_mask[:,:,None]\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(good_mask)\n",
        "        plt.title(\"Good mask\")\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(good_grape)\n",
        "        plt.title(\"Good grape\")\n",
        "        plt.show()     \n",
        "\n",
        "        os.makedirs(\"./notebooks/inputs/\", exist_ok=True)\n",
        "        imageio.imsave(\"./notebooks/inputs/good_grape.jpg\", img_good)\n",
        "        imageio.imsave(\"./notebooks/inputs/bad_grape.jpg\", img_bad) \n",
        "        save_segmentations(img_good, good_masks, output_folder=\"./notebooks/good_masks/\")\n",
        "        save_segmentations(img_bad, bad_masks, output_folder=\"./notebooks/bad_masks/\")\n",
        "\n",
        "    # Rotate the bad grape to match the orientation of the good grape\n",
        "    bad_grape, bad_mask = rotate_grape(bad_grape, bad_mask, good_mask, plot)\n",
        "\n",
        "    # Scale the bad grape to match the size of the good grape\n",
        "    bad_grape, bad_mask = scale_grape(bad_grape, bad_mask, good_mask, plot)\n",
        "\n",
        "    # Blend the bad grape onto the good image\n",
        "    blended = PoissonBlending(bad_grape, img_good, bad_mask, good_mask, cv2.NORMAL_CLONE, plot)\n",
        "\n",
        "    if plot:\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(blended)\n",
        "        plt.title(\"Blended image\")\n",
        "        plt.show()\n",
        "        os.makedirs(\"./notebooks/output/\", exist_ok=True)\n",
        "        imageio.imsave(\"./notebooks/output/blended.jpg\", blended)\n",
        "        \n",
        "    return blended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1hHKfHJTlklh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images:   0%|          | 0/111 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "mask_generator = get_mask_generator(cfg)\n",
        "good_image_paths, bad_image_paths = read_file_list(cfg[\"file_paths\"][0])\n",
        "log_folder = os.path.join(cfg[\"output_paths\"][0], \"logs\")\n",
        "os.makedirs(log_folder, exist_ok=True)\n",
        "\n",
        "num_good_images = len(good_image_paths)\n",
        "num_bad_images = len(bad_image_paths)\n",
        "for index, bad_image_path in tqdm(enumerate(bad_image_paths), desc=\"Processing images\", total=num_bad_images):\n",
        "    good_image_path = random.choice(good_image_paths)\n",
        "\n",
        "    img_good = cv2.imread(good_image_path)\n",
        "    img_good = cv2.cvtColor(img_good, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_bad = cv2.imread(bad_image_path)\n",
        "    img_bad = cv2.cvtColor(img_bad, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # img_good = resize_image(good_image_path, cfg[\"target_size\"])\n",
        "    # img_bad = resize_image(bad_image_path, cfg[\"target_size\"])\n",
        "\n",
        "    new_img = generate_synthetic_image(cfg, img_good, img_bad, mask_generator, plot=True)\n",
        "    \n",
        "    write_log(index, good_image_path, bad_image_path, log_folder)\n",
        "    imageio.imsave(f\"{cfg['output_paths'][0]}/anomaly_{index}.jpg\", new_img)\n",
        "\n",
        "print(\"Synthetic images generated successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXxf8ENamf6s",
        "PhQYz8p-fRf2",
        "huck8oxNgm_F"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
