{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valerio98-lab/Anomaly_Det_on_fictious_dataset/blob/main/Grapes_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7c0041e",
      "metadata": {
        "id": "b7c0041e"
      },
      "source": [
        "# Estrazione automatica acini SAM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b71431",
      "metadata": {
        "id": "c0b71431"
      },
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4fe300fb",
      "metadata": {
        "id": "4fe300fb"
      },
      "outputs": [],
      "source": [
        "using_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0685a2f5",
      "metadata": {
        "id": "0685a2f5",
        "outputId": "774353f4-b74e-4dcf-a998-a3afc5694def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.1.0+cu121\n",
            "Torchvision version: 0.16.0+cu121\n",
            "CUDA is available: True\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-dothldb9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-dothldb9\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: segment-anything\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36587 sha256=54345f13f7d007fdbef223434080c0fb0f41a703c44a277fe7802e0430d7017f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i1spuhdc/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "Successfully built segment-anything\n",
            "Installing collected packages: segment-anything\n",
            "Successfully installed segment-anything-1.0\n",
            "--2023-12-18 12:06:48--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.44, 18.165.83.35, 18.165.83.91, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
            "Saving to: ‘sam_vit_h_4b8939.pth’\n",
            "\n",
            "sam_vit_h_4b8939.pt 100%[===================>]   2.39G   189MB/s    in 11s     \n",
            "\n",
            "2023-12-18 12:07:00 (213 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if using_colab:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"Torchvision version:\", torchvision.__version__)\n",
        "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2bc687",
      "metadata": {
        "id": "fd2bc687"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "560725a2",
      "metadata": {
        "id": "560725a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "74b6e5f0",
      "metadata": {
        "id": "74b6e5f0"
      },
      "outputs": [],
      "source": [
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "q5o8mzdox22s",
        "outputId": "1d127d88-4f90-4e55-c78d-3ac97c74218f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "q5o8mzdox22s",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b3d6b2",
      "metadata": {
        "id": "00b3d6b2"
      },
      "source": [
        "## Extraction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Inserisci il percorso di input:\n",
        "input_path = '' #@param {type:\"string\"}\n",
        "#@markdown Inserisci il percorso di output:\n",
        "output_path = '' #@param {type:\"string\"}\n",
        "#@markdown Intersection Over Union Thresh (Default=0.90)\n",
        "pred_iou_thresh= 0.90 #@param {type:\"number\"}\n",
        "#@markdown Threshold confidenza predizione (Default=0.92)\n",
        "stability_score_thresh = 0.92 #@param {type:\"number\"}\n",
        "#@markdown area minima delle maschere (Default=10000)\n",
        "min_mask_region_area= 10000 #@param {type:\"integer\"}\n",
        "\n",
        "def compute_dimension_and_submatrix(grape, output_path, img, i)->None:\n",
        "\n",
        "    img_name = img.split(\".jpg\")[0]\n",
        "\n",
        "    rows_mask, cols_mask, _ = np.where(grape!= 0)\n",
        "\n",
        "    min_row, max_row = np.min(rows_mask), np.max(rows_mask)\n",
        "    min_col, max_col = np.min(cols_mask), np.max(cols_mask)\n",
        "\n",
        "    height_mask = max_row - min_row + 1\n",
        "    width_mask = max_col - min_col + 1\n",
        "\n",
        "    submatrix = grape[min_row:max_row+1, min_col:max_col+1]\n",
        "    submatrix_uint8 = np.where(submatrix, 255, 0).astype(np.uint8)\n",
        "    imageio.imsave(f\"{output_path}/{img_name}_mask_{i}.jpg\", submatrix)\n",
        "    #return submatrix\n",
        "\n",
        "\n",
        "def main(input_path, output_path, min_mask_region_area, stability_score_thresh, pred_iou_thresh):\n",
        "  grapes_dir = input_path\n",
        "  lista_img = os.listdir(grapes_dir)\n",
        "  k = 0\n",
        "\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "  sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "  model_type = \"vit_h\"\n",
        "\n",
        "  device = \"cuda\"\n",
        "\n",
        "  sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "  sam.to(device=device)\n",
        "\n",
        "  mask_generator = SamAutomaticMaskGenerator(\n",
        "  model=sam,\n",
        "  points_per_side=32,\n",
        "  pred_iou_thresh=pred_iou_thresh,\n",
        "  stability_score_thresh=stability_score_thresh,\n",
        "  crop_n_layers=1,\n",
        "  crop_n_points_downscale_factor=2,\n",
        "  min_mask_region_area=min_mask_region_area,\n",
        "  )\n",
        "\n",
        "  for img in lista_img:\n",
        "    if img.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "      k+=1\n",
        "      print(f\"Immagine {k} di {len(lista_img)}\")\n",
        "      path = os.path.join(grapes_dir, img)\n",
        "      print(img)\n",
        "      image = cv2.imread(path)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      masks2 = mask_generator.generate(image)\n",
        "      print(\"Numero di maschere individuate: \", len(masks2))\n",
        "      #masks2 = mask_generator.postprocess_small_regions(masks2, min_mask_region_area, 0.86)\n",
        "      new_dict = []\n",
        "      for elem in masks2:\n",
        "          if elem['area'] > min_mask_region_area:\n",
        "              new_dict.append(elem)\n",
        "      mask_sorted = sorted_anns = sorted(new_dict, key=(lambda x: x['area']), reverse=True)\n",
        "      print(\"Numero di maschere rimanenti in base all'area minima: \", len(mask_sorted))\n",
        "      for i in range(len(mask_sorted)):\n",
        "        good_mask_unit8 = (mask_sorted[i]['segmentation'].astype(np.uint8)) * 255\n",
        "        good_grape = cv2.bitwise_and(image, image, mask=good_mask_unit8)\n",
        "        compute_dimension_and_submatrix(good_grape, output_path, img, i)\n",
        "\n",
        "print(f\"Parametri inseriti: \\n Input: {input_path}\\n Output: {output_path}\\n Pred_iou: {pred_iou_thresh} \\n Stability_score: {stability_score_thresh} \\n min_mask: {min_mask_region_area}\")\n",
        "check = input(\"\\nI parametri sono corretti? {y/n}\")\n",
        "if check.lower()==\"y\":\n",
        "  main(input_path, output_path, min_mask_region_area, stability_score_thresh, pred_iou_thresh)\n",
        "else:\n",
        "  print(\"Exit\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KLqB7tGjVGRK",
        "outputId": "0eb89b1d-1085-49d9-90fe-023948892505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KLqB7tGjVGRK",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametri inseriti: \n",
            " Input: /content/ek\n",
            " Output: /content/ak\n",
            " Pred_iou: 0.9 \n",
            " Stability_score: 0.92 \n",
            " min_mask: 10000\n",
            "\n",
            "I parametri sono corretti? {y/n}y\n",
            "Immagine 1 di 1\n",
            "IMG_20210924_124738392_HDR_00.jpg\n",
            "Numero di maschere individuate:  54\n",
            "Numero di maschere rimanenti in base all'area minima:  13\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}